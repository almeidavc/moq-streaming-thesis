% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Introduction}\label{chapter:introduction}

% TODO: Can I talk about future predictions that are in the past as estimates?
Video streaming is the major source of traffic on the Internet, accounting for more than 75\% of the total traffic in 2022 \parencite{CiscoVisualNetworking2018}. Live Streaming itself accounted for 17\% of internet video traffic in 2022, a 15-fold increase since 2017. At the same time, low latencies are becoming increasingly more important in live streaming applications.

In live streaming systems, latency increases when the network is congested, if the network bandwidth can't keep up with the stream's bitrate. The only way to prevent the latency from increasing is to send less data. \acs{HAS}-based streaming protocols, % TODO: is it fine to use short form even though it is the first time i use the term?
such as \ac{DASH}, and \ac{HLS}, are too slow at adapting the transmission rate in order to respond to network congestion. First, clients need to explicitly request lower quality segments, which adds at least one \ac{RTT} before the client receives the lower quality segment. Second, applications using TCP as the transport layer protocol can't abort the sending of data, which has already been pushed to the TCP socket, unless the application terminates the connection. If the client requests a high quality video segment, and the network bandwdith suddendly drops, the full video segment has to be downloaded regardless. % TODO: maybe cite Curley's article in media over quic website

% TODO: Is there a point to be made here?
% Third, \ac{HAS}-based systems most commonly provide video content in a limited number of video qualities in a live streaming setting, which might not make use of the network resources optimally.However, there isn't a one-size-fits-all bitrate ladder and adapting the ladder to the characterists of the video content might lead to better QoE []. However we can't do this in live streaming.  that makes  fully utilize the network resources at a given time. If the network bandwidth drops . 
% It is not as trivial as increasing the number of steps in the bitrate ladder % TODO: Understand why and cite http://www.reznik.org/papers/PV2018_streaming.pdf, https://docs.unified-streaming.com/best-practice/content-preparation/improving-experience-recommendations.html

QUIC enables new streaming methods that are better equipped to respond to network conditions. However new streaming protocols need to be designed to fully leverage QUIC's features. Media over QUIC was developed to bridge this gap. The protocol is still in its early days, but the potential is promising. However, there doesn't exist a consensus on how to best use MoQ to stream media and as far as we know there isn't much work on comparing and evaluating different streaming protocols that use MoQ.

% TODO: Be more precise. We explore ways to leverage stream prioritization to design self-adaptive streaming protocols
In this thesis, we analyse and evaluate three streaming protocols using Media over QUIC. We make the following contributions:
\begin{itemize}
    \item We describe the architecture and implementation of a MoQ-based live streaming system (\autoref{chapter:implementation}). We explain the inner workings of our prototype, as well as subtle implementation details that might not be immediately obvious. In MoQ systems, the client has full control of how to render media, which gives a lot of flexibility and control to the application, but also increases the surface area of the implementation compared to the off-the-shelf players available for HAS-based streaming methods. % TODO: is this true?
    We haven't found any work on the challenges of implementing a MoQ-based web player. An additional goal we have is to describe this.
    \item We describe two self-adaptive techniques to prioritize latency. We propose an approach that consists in deprioritizing B-frames to degrade the quality of the video stream when the network is congested (\ref{chapter:deprioritizing_b_frames}). We also describe an approach that skips old media segments after a period of congestion (\ref{chapter:skipping_old_media}).
    \item We evaluate our approaches and show that they can achieve lower latencies (\ref{chapter:evaluation}). For each approach, we simulate multiple network environments and measure relevant metrics. We also present the testbed that we've used for this purpose. Additionally, we present a qualitative evaluation of our approaches, where we discuss some disadvantages that are not represented in our measurements.
\end{itemize}

Media streaming falls broadly into two categories: live streaming and \ac{VOD}. In this thesis, we only concern ourselves with the former. VOD has other challenges and thus the streaming protocols are different. Achieving a low latency, which is defined as the delay between when video is captured and when video is played, is a non-goal in the context of \ac{VOD}, since the video is pre-recorded and watched later.

Furthermore, we don't cover all components of a live streaming system, that are nonetheless necessary for a fully working system. We assume a simple architecture, consisting solely of a client and an origin server. We don't discuss the use of relays, which are crucial to scale the delivery of media to a large number of users. In this work, we also restrict ourselves to the streaming of video content. We don't consider audio, and how it interacts with video. In addition, our focus lies on the media distribution part of the pipeline. We don't discuss media contribution or ingestion. In our prototype contribution happens at the server, such that media doesn't need to be ingested over the network.