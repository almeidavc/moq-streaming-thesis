% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Conclusion}\label{chapter:conclusion}
In this thesis, we studied the design and implementation of a live streaming system using \ac{MoQ}. We first described an implementation of a prototype live streaming system consisting of an origin server and a client. We then presented two streaming protocols that use stream prioritization to decrease latency. In our first approach, the idea is to use the B-frames as an enhancement layer that we can drop to save bandwidth when the network is congested. In order to achieve this, we transmit B-frames in their own streams and assign them a low priority while transmitting the I- and P-frames in a single stream with a high priority. We then describe a second approach, in which we skip old video by prioritizing new \acp{GoP} over old ones. Similar to Warp, we map each GoP to a separate stream and assign newer GoPs a higher priority. We evaluated the performance of these two streaming protocols by measuring the latency for a variety of network profiles and presented our results.

Deprioritizing B-frames results in slightly lower latencies than transmitting all frames in the same stream with the same priority, but the effect is not significant. In cases where the network bandwidth slightly drops below the stream's bitrate for an extended period of time, the extra bandwidth allocated to the base layer can help slow down the rate at which latency increases and reduce the number of buffering events. However, this is an exception, as in the majority of most network bandwidth patterns, deprioritizing B-frames results in a similar performance to transmitting B-frames with the same priority as I- and P-frames. This is because B-frames make up only a small amount of the total bitrate. Finding other ways to divide the video stream into base and enhancement layers, such that the enhancement layer constitutes a larger portion of the total bitrate, can enable new streaming protocols that can trade off stream quality for latency more aggressively.

We also conclude that an approach that doesn't prioritize across the temporal dimension cannot be optimal. To prevent the latency from increasing, the stream's bitrate must be below the network bandwidth, and one can only decrease the stream's bitrate by degrading the stream quality until a certain point. Even if one could drastically reduce the stream's bitrate while maintaining a watchable quality, clearly, if the network throughput drops to zero due to a network fault, the stream will inevitably lag behind, causing the old video to queue. When this occurs, the server must skip old video segments that are queued so that the client resumes playback at the live edge in order to ensure the minimum possible latency. To do this, we can skip old GoPs, which we've shown consistently achieves lower latencies.

We can design and implement live streaming systems using Media over QUIC that are able to respond to congestion in a variety of new and improved ways by leveraging QUIC. Using QUIC's features, such as concurrent independent streams and stream prioritization, it's possible to achieve low latency even under unfavorable network conditions by trading off stream quality and skipping parts of the live stream.

In future work, we plan to explore alternative ways of dividing the stream into base and enhancement layers. One promising approach is to use \ac{SVC}, which encodes the video stream into a hierarchy of layers that can be dropped to reduce quality, making it a natural fit. Another option is to use \ac{RFI} to force P-frames to reference only I-frames, allowing P-frames to be dropped independently without affecting the decodability of other P-frames. This would allow for strategies like sending every other P-frame in the enhancement layer to achieve temporal scalability. Additionally, an interesting direction for future work is to send B-frames unreliably using QUIC's datagram feature.